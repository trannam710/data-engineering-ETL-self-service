version: '3.8'

services:
  postgres:
    image: postgres:15
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    ports:
      - "5432:5432"
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data
    networks:
      - airflow_kafka

  airflow-webserver:
    build: .
    restart: always
    depends_on:
      - airflow-init
      # - spark-master
      - postgres
    user: "${AIRFLOW_UID}" # Thêm dòng này
    env_file:
      .env
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__WEBSERVER__SECRET_KEY: mysecretkey
      AIRFLOW__WEBSERVER__WORKERS: 2
      # AIRFLOW_CONN_AWS_S3_CONN: aws://${AWS_ACCESS_KEY_ID_VALUE}:${AWS_SECRET_ACCESS_KEY_VALUE}@s3.amazonaws.com/?region_name=ap-southeast-1
      PYTHONPATH: "/opt/airflow"
    ports:
      - "8080:8080"
    command: webserver
    volumes:
      - ./operators:/opt/airflow/operators
      - ./dags:/opt/airflow/dags
      - ./configs:/opt/airflow/configs
    networks:
      - airflow_kafka

  airflow-scheduler:
    build: .
    restart: always
    depends_on:
      - airflow-init
      # - spark-master
      - postgres
    user: "${AIRFLOW_UID}" # Thêm dòng này
    env_file:
      .env
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__WEBSERVER__SECRET_KEY: mysecretkey
      PYTHONPATH: "/opt/airflow"
    command: scheduler
    volumes:
      - ./operators:/opt/airflow/operators
      - ./dags:/opt/airflow/dags
      - ./configs:/opt/airflow/configs
    networks:
      - airflow_kafka

  airflow-init:
    build: .
    depends_on:
      - postgres
    user: "${AIRFLOW_UID}" # Thêm dòng này
    env_file:
      .env
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
    entrypoint: >
      bash -c "
        airflow db init &&
        airflow users create --username airflow --firstname Airflow --lastname Admin --role Admin --email airflow@example.com --password airflow
      "
    networks:
      - airflow_kafka

volumes:
  postgres-db-volume:
  data_lake:
  RAW_DATA:

networks:
  airflow_kafka:
    driver: bridge